

### 关键词

人工智能、机器学习、深度学习、生成式人工智能



#### 机器学习

监督学习

无监督学习

强化学习



#### 深度学习

神经网络分为：卷积神经网络(CNNs)、循环神经网络(RNNs)、Transformer网络





### 大模型训练

大模型训练分为3个阶段：预训练、SFT(监督微调)、RLHF(基于人类反馈的强化学习)



### 大模型分类

按场景分：

基础模型(大模型)

​	大语音模型(LLM)

​	多模态模型

​		计算机视觉模型-VLLM

​		音频处理模型



#### 大语音模型

专注于自然语言(NLP)，旨在处理语言、文章、对话等自然语言文本。通常基于深度学习架构(如Transformer模型)，经过大模型文本数据集训练而成，能够捕捉语言的复杂性，包括语法、语义、语境以及蕴含的文化和社会知识。

大语音模型典型应用包括：文本生成、问答系统、文本分类、机器编译、对话系统等。

示例：

1、GPT系列(OpenAI)：GPT-3、GPT-3.5、GPT-4等

2、Bard(Google)：用于提供信息丰富的、有创意的文本输出

3、通义千问(阿里云)



#### 多模态模型

多模态模型能够处理和理解来自不同感知通道（文本、图像、音频、视频等）的数据，并在这些模态之间建立关联和交互。

能够整合不同类型的输入信息，进行跨模态推理、生成和理解任务。

多模态大模型和应用涵盖：视觉问答、图像描述生成、跨模态检索、多媒体内容理解等领域。



### 大模型工作原理

#### 分词化(Tokenization)与词表映射

分词化是自然语言(NLP)的重要概念，它是将段落和句子分割成更小的分词(token)的过程。

分词化有不同的粒度分类：

- 词粒度(wold-level Tokenization)：西方语言，英语
- 字符粒度(Character-level)：中文，单个汉字分词化
- 子词粒度(Subword-level)：词根、词缀。处理新词(专有名词、网络用语)

每一个token都会通过预先设置好的词表，映射为一个token id，这是token的身份证，一句话最终会被表示为一个元素为token id的列表，供计算机进行下一步处理。



#### 文本生成过程





